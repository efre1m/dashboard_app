import os
import re
from datetime import datetime
from difflib import SequenceMatcher
import pandas as pd

MANUAL_FACILITY_ALIASES = {
    "dbcsH": "Debere birhan  comprehensive referral hospital",
    "adis zemen primary hospital": "Addis Zemen Primary Hospital",
    "sawla hosptal": "Sawla General General Hospital",
    "bonga g st shawo general hospital": "Bona GH",
    "nigst elleni comprehensive specialized hospital": "Nigist Eleni M/M/referral Hospital",
    "burie piraymery hospital": "Burie Aserade primary hospital",
    "dcsh": "Deberetabor comprehensive referral hospital",
    "akucsh": "Axum referral hospital",
    "abiy adiy generale hospitale": "Abyi-adi general hospital",
    "st marry g hospital axum": "St. mary general hospital",
}


def _normalize_for_matching(column_name: str) -> str:
    """Normalize column names to detect semantic matches across form versions."""
    name = column_name.strip()
    if name.startswith("reg-"):
        name = name[4:]

    # Ignore shifting autogenerated numeric suffixes in ODK labels
    name = re.sub(
        r"(reserved_name_for_field_list_labels_)\d+$",
        r"\1*",
        name,
    )
    name = re.sub(
        r"(generated_table_list_label_)\d+$",
        r"\1*",
        name,
    )

    # Treat trailing "_1" and "_" as equivalent in edge cases like POC8_1 vs POC8_
    name = re.sub(r"_1$", "_", name)
    return name


def _normalize_facility_name(value: str) -> str:
    """Normalize free-text facility names for robust matching."""
    if value is None:
        return ""
    name = str(value).strip().lower()
    name = re.sub(r"[^a-z0-9\s]", " ", name)
    name = re.sub(r"\breferral hospital\b", "rh", name)
    name = re.sub(r"\breferal hospital\b", "rh", name)
    name = re.sub(r"\bprimary hospital\b", "ph", name)
    name = re.sub(r"\bprimery hospital\b", "ph", name)
    name = re.sub(r"\bgeneral hospital\b", "gh", name)
    name = re.sub(r"\bgeneneral hospital\b", "gh", name)
    name = re.sub(r"\bgenerale hospital\b", "gh", name)
    name = re.sub(r"\bgenersle hospital\b", "gh", name)
    name = re.sub(r"\bhealth center\b", "hc", name)
    name = re.sub(r"\bcomprehensive specialized hospital\b", "csh", name)
    name = re.sub(r"\bcomprehensive specislized hospital\b", "csh", name)
    name = re.sub(r"\bcomprehensive specialist hospital\b", "csh", name)
    name = re.sub(r"\bcomprehensive specialist hospital\b", "csh", name)
    name = re.sub(r"\bhospital\b", "hosp", name)
    name = re.sub(r"\bhospitale\b", "hosp", name)
    name = re.sub(r"\bhosipital\b", "hosp", name)
    name = re.sub(r"\bhodpital\b", "hosp", name)
    name = re.sub(r"\bprimery\b", "primary", name)
    name = re.sub(r"\breferal\b", "referral", name)
    name = re.sub(r"\bspecislized\b", "specialized", name)
    name = re.sub(r"\bgeneneral\b", "general", name)
    name = re.sub(r"\bgenerale\b", "general", name)
    name = re.sub(r"\bgenersle\b", "general", name)
    name = re.sub(r"\bst\b", "saint", name)
    name = re.sub(r"\bmary\b", "marry", name)
    name = re.sub(r"\s+", " ", name).strip()
    return name


def _build_facility_lookup(mapping_df: pd.DataFrame):
    """Build normalized lookup and candidate list from mapping table."""
    exact_lookup = {}
    candidates = []
    code_to_name = {}
    for _, row in mapping_df.iterrows():
        code = str(row.get("facility code", "")).strip()
        facility_name = str(row.get("facility name", "")).strip()
        if not code or not facility_name or code.lower() == "nan":
            continue
        code_to_name[code] = facility_name

        norm_full = _normalize_facility_name(facility_name)
        if norm_full:
            exact_lookup.setdefault(norm_full, (code, facility_name))
            candidates.append((norm_full, code, facility_name))

        # Also allow exact match on base name without suffixes.
        norm_base = re.sub(r"\b(rh|ph|gh|hc|csh|hosp)\b$", "", norm_full).strip()
        if norm_base and norm_base != norm_full:
            exact_lookup.setdefault(norm_base, (code, facility_name))
            candidates.append((norm_base, code, facility_name))
    return exact_lookup, candidates, code_to_name


def _fuzzy_facility_match(raw_name: str, exact_lookup, candidates, alias_lookup):
    """Return best (code, canonical_name, method) using exact + flexible fuzzy matching."""
    normalized = _normalize_facility_name(raw_name)
    if not normalized:
        return None, None, "none"

    if normalized in exact_lookup:
        code, name = exact_lookup[normalized]
        return code, name, "exact"

    # Manual alias corrections for known recurring typos/abbreviations
    alias_target = alias_lookup.get(normalized)
    if alias_target and alias_target in exact_lookup:
        code, name = exact_lookup[alias_target]
        return code, name, "manual_alias"

    raw_tokens = set(normalized.split())
    best_score = 0.0
    best_match = (None, None)
    for cand_norm, code, canonical_name in candidates:
        cand_tokens = set(cand_norm.split())
        if not cand_tokens:
            continue

        seq_score = SequenceMatcher(None, normalized, cand_norm).ratio()
        jaccard = len(raw_tokens & cand_tokens) / max(1, len(raw_tokens | cand_tokens))
        contain_bonus = 0.12 if (normalized in cand_norm or cand_norm in normalized) else 0.0
        score = 0.65 * seq_score + 0.35 * jaccard + contain_bonus

        if score > best_score:
            best_score = score
            best_match = (code, canonical_name)

    # Flexible thresholds for human-entered names
    if best_score >= 0.52:
        return best_match[0], best_match[1], f"fuzzy:{best_score:.2f}"
    return None, None, "unmatched"


def merge_skill_forms():
    """Append skill assessment rows to final skill file using column-name alignment."""
    base_dir = os.path.dirname(__file__)
    skill_file = os.path.join(base_dir, "mentorship", "Skill_assssment_form.csv")
    final_skill_file = os.path.join(
        base_dir, "mentorship", "Final_Skill assessment_EPS_revised2.csv"
    )
    updated_skill_file = os.path.join(base_dir, "mentorship", "Skill_assssment_form.csv")
    facility_mapping_file = os.path.join(base_dir, "mentorship", "facility_code_mapping.csv")
    merged_file = os.path.join(base_dir, "mentorship", "merged_skill.csv")

    missing_files = [
        p
        for p in (skill_file, final_skill_file, facility_mapping_file)
        if not os.path.exists(p)
    ]
    if missing_files:
        raise FileNotFoundError(
            "Missing required CSV file(s): " + ", ".join(missing_files)
        )

    skill_df = pd.read_csv(skill_file)
    final_skill_df = pd.read_csv(final_skill_file)
    facility_map_df = pd.read_csv(facility_mapping_file)

    # Enrich skill data: map free-text facilityoza names to reg-hospital code.
    if "facilityoza" not in skill_df.columns:
        raise KeyError("Required column not found in skill form: facilityoza")

    exact_lookup, candidates, code_to_name = _build_facility_lookup(facility_map_df)
    alias_lookup = {
        _normalize_facility_name(k): _normalize_facility_name(v)
        for k, v in MANUAL_FACILITY_ALIASES.items()
    }
    mapped_codes = []
    mapped_names = []
    matched_count = 0
    unmatched_count = 0
    unmatched_names = []
    exact_count = 0
    fuzzy_count = 0
    manual_count = 0
    for raw_name in skill_df["facilityoza"].fillna(""):
        code, canonical_name, method = _fuzzy_facility_match(
            raw_name, exact_lookup, candidates, alias_lookup
        )
        if code:
            matched_count += 1
            if method == "exact":
                exact_count += 1
            elif method == "manual_alias":
                manual_count += 1
            else:
                fuzzy_count += 1
            canonical = code_to_name.get(str(code), canonical_name)
            mapped_codes.append(str(code))
            mapped_names.append(canonical)
        else:
            unmatched_count += 1
            mapped_codes.append("")
            mapped_names.append(raw_name)
            raw = str(raw_name).strip()
            if raw:
                unmatched_names.append(raw)

    # Update facilityoza with canonical mapped name when matched
    skill_df["facilityoza"] = mapped_names

    # Insert reg-hospital right next to facilityoza
    if "reg-hospital" in skill_df.columns:
        skill_df["reg-hospital"] = mapped_codes
    else:
        facilityoza_index = skill_df.columns.get_loc("facilityoza")
        skill_df.insert(facilityoza_index + 1, "reg-hospital", mapped_codes)

    # Persist cleaned skill assessment data before merge (as requested).
    updated_skill_output_path = updated_skill_file
    try:
        skill_df.to_csv(updated_skill_file, index=False)
    except PermissionError:
        fallback_candidates = [
            os.path.join(base_dir, "mentorship", "Skill_assssment_form_updated.csv"),
            os.path.join(
                base_dir,
                "mentorship",
                f"Skill_assssment_form_updated_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            ),
        ]
        saved = False
        for candidate in fallback_candidates:
            try:
                skill_df.to_csv(candidate, index=False)
                updated_skill_output_path = candidate
                saved = True
                break
            except PermissionError:
                continue
        if not saved:
            raise PermissionError(
                "Could not save updated skill form file; close open CSV files and retry."
            )
        print(
            "Could not overwrite Skill_assssment_form.csv (file is open). "
            f"Saved updated skill file to: {updated_skill_output_path}"
        )

    common_cols = [col for col in skill_df.columns if col in final_skill_df.columns]
    only_in_final_skill = [
        col for col in final_skill_df.columns if col not in skill_df.columns
    ]
    only_in_skill = [col for col in skill_df.columns if col not in final_skill_df.columns]

    skill_aligned = skill_df.reindex(columns=final_skill_df.columns)

    # Manual semantic mappings between source and final naming conventions
    explicit_mappings = {
        "region": "reg-region",
        "other_reg": "reg-other_reg",
        "period": "reg-round",
        "facilityoz": "reg-facilityoz",
        "facilityo": "reg-facilityozo",
        "facilityozo": "reg-facilityozo",
        "facilitya": "reg-facilityoza",
        "facilityoza": "reg-facilityoza",
        "facilityt": "reg-facilityozt",
        "facilityozt": "reg-facilityozt",
        "facilitysd": "reg-facilityozsd",
        "facilityozsd": "reg-facilityozsd",
        "facilityaf": "reg-facilityozaf",
        "facilityozaf": "reg-facilityozaf",
    }
    applied_mappings = []
    for source_col, target_col in explicit_mappings.items():
        if source_col in skill_df.columns and target_col in skill_aligned.columns:
            skill_aligned[target_col] = skill_df[source_col]
            applied_mappings.append(f"{source_col} -> {target_col}")

    # Heuristic mappings for "almost same" ODK-generated names
    unmatched_source = [
        c
        for c in only_in_skill
        if c in skill_df.columns and c not in explicit_mappings
    ]
    unmatched_target = [
        c
        for c in only_in_final_skill
        if c in skill_aligned.columns and c not in explicit_mappings.values()
    ]
    target_by_norm = {_normalize_for_matching(c): c for c in unmatched_target}

    for source_col in unmatched_source:
        normalized = _normalize_for_matching(source_col)
        target_col = target_by_norm.get(normalized)
        if target_col:
            skill_aligned[target_col] = skill_df[source_col]
            applied_mappings.append(f"{source_col} -> {target_col}")

    merged_df = pd.concat([final_skill_df, skill_aligned], ignore_index=True)

    mapped_sources = {m.split(" -> ")[0] for m in applied_mappings}
    mapped_targets = {m.split(" -> ")[1] for m in applied_mappings}
    remaining_only_in_final = [c for c in only_in_final_skill if c not in mapped_targets]
    remaining_only_in_skill = [c for c in only_in_skill if c not in mapped_sources]

    print(f"Merged columns ({len(common_cols)}): {common_cols}")
    print(
        f"Facility name-to-code mapping via facilityoza -> reg-hospital: "
        f"matched={matched_count}, unmatched={unmatched_count}, "
        f"exact={exact_count}, manual={manual_count}, fuzzy={fuzzy_count}"
    )
    print(
        "Updated skill file path (normalized names + reg-hospital): "
        f"{updated_skill_output_path}"
    )
    if unmatched_names:
        # Show a sample list for cleanup in source data.
        sample_unmatched = sorted(set(unmatched_names))[:25]
        print(f"Unmatched facilityoza samples ({len(sample_unmatched)} shown): {sample_unmatched}")
    print(f"Applied explicit/heuristic mappings ({len(applied_mappings)}): {applied_mappings}")
    print(
        "Columns only in Final_Skill assessment_EPS_revised2.csv "
        f"before mapping ({len(only_in_final_skill)}): {only_in_final_skill}"
    )
    print(
        "Columns only in Skill_assssment_form.csv "
        f"before mapping ({len(only_in_skill)}): {only_in_skill}"
    )
    print(
        "Remaining only in Final_Skill assessment_EPS_revised2.csv "
        f"after mapping ({len(remaining_only_in_final)}): {remaining_only_in_final}"
    )
    print(
        "Remaining only in Skill_assssment_form.csv "
        f"after mapping ({len(remaining_only_in_skill)}): {remaining_only_in_skill}"
    )
    try:
        merged_df.to_csv(merged_file, index=False)
        print(f"Output path: {merged_file}")
    except PermissionError:
        print(f"Could not write output file (permission denied): {merged_file}")
        print("Close the file if it is open, then run again.")

    return merged_file


if __name__ == "__main__":
    merge_skill_forms()
